{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c451a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a97aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325a73b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('labels.csv'),Path('train'),Path('valid')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202d3d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046f4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png'),Path('train/3/10093.png'),Path('train/3/10097.png'),Path('train/3/10099.png'),Path('train/3/10116.png'),Path('train/3/10125.png'),Path('train/3/10137.png'),Path('train/3/10141.png'),Path('train/3/10144.png'),Path('train/3/10155.png'),Path('train/3/10161.png')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b783e8e",
   "metadata": {},
   "source": [
    "To be more specific, here are the steps that we are going to require, to turn this function into a machine learning classifier:\n",
    "\n",
    "Initialize the weights.\n",
    "\n",
    "For each image, use these weights to predict whether it appears to be a 3 or a 7.\n",
    "\n",
    "Based on these predictions, calculate how good the model is (its loss).\n",
    "\n",
    "Calculate the gradient, which measures for each weight, how changing that weight would change the loss\n",
    "\n",
    "Step (that is, change) all the weights based on that calculation.\n",
    "\n",
    "Go back to the step 2, and repeat the process.\n",
    "\n",
    "Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8083ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f500fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dd6eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f6d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd43a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) # 1 for 3, 0 for 7\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d4b3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c48925f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70619d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e62396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): \n",
    "    return (torch.randn(size)*std).requires_grad_() #random normal distribution to initialize weights\n",
    "\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "\n",
    "# In neural networks, the w in the equation y=w*x+b is called the weights, and the b is called the bias. Together, the weights and bias make up the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9efac2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13.7164], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fa4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.7165],\n",
       "        [21.9142],\n",
       "        [21.3839],\n",
       "        ...,\n",
       "        [ 5.1241],\n",
       "        [ 9.9235],\n",
       "        [10.0164]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): \n",
    "    return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dca329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [ True],\n",
       "        ...,\n",
       "        [False],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7b198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49249759316444397"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b41fb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49249759316444397"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()\n",
    "# A very small change in the value of a weight will often not actually change the accuracy at all. \n",
    "# This means it is not useful to use accuracy as a loss functionâ€”if we do, most of the time our gradients will actually be 0, and the model will not be able to learn from that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bef15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7d3e6",
   "metadata": {},
   "source": [
    "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. This is why we designed a loss function that would respond to small changes in confidence level. This requirement means that sometimes it does not really reflect exactly what we are trying to achieve, but is rather a compromise between our real goal and a function that can be optimized using its gradient. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd00cc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e528a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6198fe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bffd4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.7165],\n",
       "        [21.9142],\n",
       "        [21.3839],\n",
       "        [17.4212]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a32e258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6822e-07, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b070c55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-3.8301e-08), tensor([-2.6822e-07]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape,weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23a5f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc8ef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6602e-08), tensor([-5.3644e-07]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d694f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.1490e-07), tensor([-8.0466e-07]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.mean(),bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "335cb034",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e0ae162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9c16fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7afe574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaabe527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5950e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d3d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4961"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c471fa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c9f3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812 0.8096 0.894 0.9277 0.9429 0.9541 0.9585 0.9614 0.9658 0.9682 0.9687 0.9692 0.9697 0.9702 0.9716 0.9731 0.9736 0.9746 0.9751 0.976 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fb8bba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1) # linear is init_params and linear combined\n",
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4090ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: \n",
    "            p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: \n",
    "            p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f9d7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ff0f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e53a2824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4606"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5289fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "533f9b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.7349 0.8613 0.917 0.9355 0.9507 0.9565 0.9634 0.9658 0.9678 0.9702 0.9717 0.9746 0.9751 0.9761 0.977 0.9775 0.978 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "764b0301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.9125 0.7246 0.8828 0.9214 0.9399 0.9521 0.9604 0.9648 0.9663 0.9687 0.9712 0.9721 0.9741 0.9751 0.9761 0.977 0.9775 0.978 0.9785 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr) # SGD is BasicOptim but better\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8608e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a749d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "702333dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.637148</td>\n",
       "      <td>0.503167</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.435343</td>\n",
       "      <td>0.248319</td>\n",
       "      <td>0.776251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.163249</td>\n",
       "      <td>0.163084</td>\n",
       "      <td>0.854269</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073413</td>\n",
       "      <td>0.100785</td>\n",
       "      <td>0.916094</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.040210</td>\n",
       "      <td>0.074992</td>\n",
       "      <td>0.934249</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027173</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.051595</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>0.045526</td>\n",
       "      <td>0.962709</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018046</td>\n",
       "      <td>0.041223</td>\n",
       "      <td>0.965653</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, lr=lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
